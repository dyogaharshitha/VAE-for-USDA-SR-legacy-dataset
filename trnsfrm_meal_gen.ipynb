{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyogaharshitha/VAE-for-USDA-SR-legacy-dataset/blob/main/trnsfrm_meal_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUAMbgK_RRBk"
      },
      "source": [
        "# Meal plan generator\n",
        "\n",
        "Author: [D Yoga Harshitha](https://linkedin.com/in/dyogaharshitha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WjXKHEu9-ck",
        "outputId": "df327f9f-e215-49d5-f0ec-0e80f9ed1f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkqXwkB3XVvR",
        "outputId": "1665ca84-8b6c-48da-b63e-62e903b2c750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.6.4-py3-none-any.whl (584 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.8/584.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting namex (from keras-core->keras-nlp)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Installing collected packages: namex, keras-core, tensorflow-text, keras-nlp\n",
            "Successfully installed keras-core-0.1.7 keras-nlp-0.6.4 namex-0.0.7 tensorflow-text-2.15.0\n",
            "Collecting positional-encodings[tensorflow]\n",
            "  Downloading positional_encodings-6.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from positional-encodings[tensorflow]) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from positional-encodings[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->positional-encodings[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->positional-encodings[tensorflow]) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->positional-encodings[tensorflow]) (3.2.2)\n",
            "Installing collected packages: positional-encodings\n",
            "Successfully installed positional-encodings-6.0.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-nlp\n",
        "!pip install positional-encodings[tensorflow]\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk-cbdVUXhOe",
        "outputId": "af567768-35e3-4ddd-e00d-cd7be6b2ba52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import keras_nlp\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FiYccXnWdva"
      },
      "source": [
        "Keys USDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBna_GKQWiPe",
        "outputId": "b9ad055e-36b9-47fb-c004-413b048db228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Baked Foods' 'Snacks' 'Sweets' 'Vegetables' 'American Indian'\n",
            " 'Restaurant Foods' 'Beverages' 'Fats and Oils' 'Meats'\n",
            " 'Dairy and Egg Products' 'Baby Foods' 'Breakfast Cereals'\n",
            " 'Soups and Sauces' 'Beans and Lentils' 'Fish' 'Fruits' nan\n",
            " 'Grains and Pasta' 'Nuts and Seeds' 'Prepared Meals' 'Fast Foods'\n",
            " 'Spices and Herbs' 'Dairy and Egg Products ']\n",
            "cholestol13  vita mcg20  vit c21\n",
            "   Cereals  Vegetables  nuts  pulses  dairy  non-veg  processd  Calories  \\\n",
            "0      0.7         0.0   0.0     0.0    0.0        0         0     307.0   \n",
            "1      0.7         0.0   0.0     0.0    0.0        0         0     330.0   \n",
            "2      0.7         0.0   0.0     0.0    0.0        0         0     377.0   \n",
            "3      0.7         0.0   0.0     0.0    0.0        0         0     232.0   \n",
            "4      0.7         0.0   0.0     0.0    0.0        0         0     273.0   \n",
            "\n",
            "   Fat (g)  Protein (g)  ...  Histidine (mg)  Alanine (mg)  \\\n",
            "0    13.24         5.88  ...             0.0           0.0   \n",
            "1    11.27         4.34  ...             0.0           0.0   \n",
            "2     3.70         6.10  ...             0.0           0.0   \n",
            "3     1.80         8.00  ...             0.0           0.0   \n",
            "4     9.22         6.58  ...           143.0         249.0   \n",
            "\n",
            "   Aspartic acid (mg)  Glutamic acid (mg)  Glycine (mg)  Proline (mg)  \\\n",
            "0                 0.0                 0.0           0.0           0.0   \n",
            "1                 0.0                 0.0           0.0           0.0   \n",
            "2                 0.0                 0.0           0.0           0.0   \n",
            "3                 0.0                 0.0           0.0           0.0   \n",
            "4               406.0              1614.0         214.0         559.0   \n",
            "\n",
            "   Serine (mg)  Hydroxyproline (mg)  Alcohol (g)  Caffeine (mg)  \n",
            "0          0.0                  0.0          0.0            0.0  \n",
            "1          0.0                  0.0          0.0            0.0  \n",
            "2          0.0                  0.0          0.0            0.0  \n",
            "3          0.0                  0.0          0.0            0.0  \n",
            "4        347.0                  0.0          0.0            0.0  \n",
            "\n",
            "[5 rows x 100 columns]\n",
            "(14164, 100)\n"
          ]
        }
      ],
      "source": [
        "usda_food = pd.read_csv(r'/content/drive/MyDrive/DietApp/Fooddata/usda_sr_all_foods.csv')\n",
        "print(usda_food[\"Food Group\"].unique())\n",
        "usda_food = usda_food.fillna(0)\n",
        "usda_food[\"Cereals\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Baked Foods\" else 1 if x==\"Breakfast Cereals\" else 1 if x==\"Grains and Pasta\" else 0.5 if x==\"Baby Foods\" else 0)\n",
        "usda_food[\"Fruits\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Fruits\" else 0 )\n",
        "usda_food[\"Vegetables\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Vegetables\" else 0 )\n",
        "usda_food[\"nuts\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Nuts and Seeds\" else 0.3 if x==\"Baby Foods\" else 0)\n",
        "usda_food[\"pulses\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Beans and Lentils\" else 0.3 if x==\"Baby Foods\" else 0 )\n",
        "usda_food[\"dairy\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Dairy and Egg Products\" else 0 )\n",
        "usda_food[\"non-veg\"] = usda_food[\"Food Group\"].apply(lambda x: 1 if x==\"Meats\" else 1 if x==\"Fish\" else 0 )\n",
        "usda_food[\"processd\"] = usda_food[\"Food Group\"].apply(lambda x: 1 if x==\"Beverages\" else 1 if x==\"Fast Foods\" else 1 if x==\"Soups and Sauces\" else 0 )\n",
        "usda_food.drop(columns=[\"Food Group\",\"name\",\"ID\",\"200 Calorie Weight (g)\",\"PRAL score\"], inplace= True)\n",
        "usda_cols = usda_food.columns.to_list()\n",
        "usda_cols = [\"Cereals\",\"Vegetables\",\"nuts\",\"pulses\",\"dairy\",\"non-veg\",\"processd\"]+usda_cols[:-8]\n",
        "print(\"cholestol\"+str(usda_cols.index(\"Cholesterol (mg)\"))+\"  vita mcg\"+str(usda_cols.index(\"Vitamin A, RAE (mcg)\"))+\"  vit c\"+str(usda_cols.index(\"Vitamin C (mg)\")))\n",
        "usda_food = usda_food[usda_cols]\n",
        "print(usda_food.head()); print(usda_food.shape);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdhWwCpOEZmk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdRodXNnX_Me"
      },
      "source": [
        "cluster and select"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aZu9zCaWoNC",
        "outputId": "8f374943-e325-46a9-d5a5-1c2844a12c7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "clstr = KMeans(500)\n",
        "clstr.fit(usda_food)\n",
        "usda_clstr = clstr.transform(usda_food)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "XDjY8gHkWiMB",
        "outputId": "f7daef78-daa0-44d4-e8d1-87c7742b103f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a13df348-4a3f-4a4a-990f-dd30649dd0d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cereals</th>\n",
              "      <th>Vegetables</th>\n",
              "      <th>nuts</th>\n",
              "      <th>pulses</th>\n",
              "      <th>dairy</th>\n",
              "      <th>non-veg</th>\n",
              "      <th>processd</th>\n",
              "      <th>Calories</th>\n",
              "      <th>Fat (g)</th>\n",
              "      <th>Protein (g)</th>\n",
              "      <th>...</th>\n",
              "      <th>Histidine (mg)</th>\n",
              "      <th>Alanine (mg)</th>\n",
              "      <th>Aspartic acid (mg)</th>\n",
              "      <th>Glutamic acid (mg)</th>\n",
              "      <th>Glycine (mg)</th>\n",
              "      <th>Proline (mg)</th>\n",
              "      <th>Serine (mg)</th>\n",
              "      <th>Hydroxyproline (mg)</th>\n",
              "      <th>Alcohol (g)</th>\n",
              "      <th>Caffeine (mg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>13.24</td>\n",
              "      <td>5.88</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>11.27</td>\n",
              "      <td>4.34</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>8.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>9.22</td>\n",
              "      <td>6.58</td>\n",
              "      <td>...</td>\n",
              "      <td>143.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>1614.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>559.0</td>\n",
              "      <td>347.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>9.40</td>\n",
              "      <td>6.92</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12695</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>32.19</td>\n",
              "      <td>2.92</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12696</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>13.13</td>\n",
              "      <td>1.74</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13804</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>764.0</td>\n",
              "      <td>86.30</td>\n",
              "      <td>0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13813</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>64.20</td>\n",
              "      <td>0.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14163</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>892.0</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a13df348-4a3f-4a4a-990f-dd30649dd0d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a13df348-4a3f-4a4a-990f-dd30649dd0d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a13df348-4a3f-4a4a-990f-dd30649dd0d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3100cc38-6309-460f-8362-2153ed48a8f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3100cc38-6309-460f-8362-2153ed48a8f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3100cc38-6309-460f-8362-2153ed48a8f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9575fe7e-4fb0-494f-9b7b-c4fea444ecd7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('usda_clstr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9575fe7e-4fb0-494f-9b7b-c4fea444ecd7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('usda_clstr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Cereals  Vegetables  nuts  pulses  dairy  non-veg  processd  Calories  \\\n",
              "0          0.7         0.0   0.0     0.0    0.0        0         0     307.0   \n",
              "1          0.7         0.0   0.0     0.0    0.0        0         0     330.0   \n",
              "3          0.7         0.0   0.0     0.0    0.0        0         0     232.0   \n",
              "4          0.7         0.0   0.0     0.0    0.0        0         0     273.0   \n",
              "6          0.7         0.0   0.0     0.0    0.0        0         0     289.0   \n",
              "...        ...         ...   ...     ...    ...      ...       ...       ...   \n",
              "12695      0.0         0.0   0.0     0.0    0.0        0         0     529.0   \n",
              "12696      0.0         0.7   0.0     0.0    0.0        0         0     193.0   \n",
              "13804      0.0         0.0   0.0     0.0    0.0        0         0     764.0   \n",
              "13813      0.0         0.0   0.0     0.0    0.0        0         0     594.0   \n",
              "14163      0.0         0.0   0.0     0.0    0.0        0         0     892.0   \n",
              "\n",
              "       Fat (g)  Protein (g)  ...  Histidine (mg)  Alanine (mg)  \\\n",
              "0        13.24         5.88  ...             0.0           0.0   \n",
              "1        11.27         4.34  ...             0.0           0.0   \n",
              "3         1.80         8.00  ...             0.0           0.0   \n",
              "4         9.22         6.58  ...           143.0         249.0   \n",
              "6         9.40         6.92  ...             0.0           0.0   \n",
              "...        ...          ...  ...             ...           ...   \n",
              "12695    32.19         2.92  ...             0.0           0.0   \n",
              "12696    13.13         1.74  ...             0.0           0.0   \n",
              "13804    86.30         0.29  ...             0.0           0.0   \n",
              "13813    64.20         0.90  ...             0.0           0.0   \n",
              "14163   100.00         0.00  ...             0.0           0.0   \n",
              "\n",
              "       Aspartic acid (mg)  Glutamic acid (mg)  Glycine (mg)  Proline (mg)  \\\n",
              "0                     0.0                 0.0           0.0           0.0   \n",
              "1                     0.0                 0.0           0.0           0.0   \n",
              "3                     0.0                 0.0           0.0           0.0   \n",
              "4                   406.0              1614.0         214.0         559.0   \n",
              "6                     0.0                 0.0           0.0           0.0   \n",
              "...                   ...                 ...           ...           ...   \n",
              "12695                 0.0                 0.0           0.0           0.0   \n",
              "12696                 0.0                 0.0           0.0           0.0   \n",
              "13804                 0.0                 0.0           0.0           0.0   \n",
              "13813                 0.0                 0.0           0.0           0.0   \n",
              "14163                 0.0                 0.0           0.0           0.0   \n",
              "\n",
              "       Serine (mg)  Hydroxyproline (mg)  Alcohol (g)  Caffeine (mg)  \n",
              "0              0.0                  0.0          0.0            0.0  \n",
              "1              0.0                  0.0          0.0            0.0  \n",
              "3              0.0                  0.0          0.0            0.0  \n",
              "4            347.0                  0.0          0.0            0.0  \n",
              "6              0.0                  0.0          0.0            0.0  \n",
              "...            ...                  ...          ...            ...  \n",
              "12695          0.0                  0.0          0.0            0.0  \n",
              "12696          0.0                  0.0          0.0            0.0  \n",
              "13804          0.0                  0.0          0.0            0.0  \n",
              "13813          0.0                  0.0          0.0            0.0  \n",
              "14163          0.0                  0.0          0.0            0.0  \n",
              "\n",
              "[500 rows x 100 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "usda_clstr = usda_food.copy(deep=True)\n",
        "usda_clstr['clustr']=clstr.labels_\n",
        "usda_clstr = usda_clstr.groupby('clustr',as_index=False).nth(0)\n",
        "usda_clstr.drop('clustr',axis=1,inplace=True)\n",
        "usda_clstr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSz8__d_ZVCh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNDSGIyLZU-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqI40_QgRWgT"
      },
      "source": [
        "Prepare queries :  the input spec for meal - age, diet type, cal req, meal type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11f1BpT3RRTg",
        "outputId": "8552872c-4541-40a1-b89a-27bea2ea8086"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0700ea93-b43f-44d0-a53d-64fb890649d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>total_qty_max</th>\n",
              "      <th>Cereal</th>\n",
              "      <th>Vegetables</th>\n",
              "      <th>nuts</th>\n",
              "      <th>pulses</th>\n",
              "      <th>dairy</th>\n",
              "      <th>non-veg</th>\n",
              "      <th>processd</th>\n",
              "      <th>Calories</th>\n",
              "      <th>...</th>\n",
              "      <th>Histidine (mg)</th>\n",
              "      <th>Alanine (mg)</th>\n",
              "      <th>Aspartic acid (mg)</th>\n",
              "      <th>Glutamic acid (mg)</th>\n",
              "      <th>Glycine (mg)</th>\n",
              "      <th>Proline (mg)</th>\n",
              "      <th>Serine (mg)</th>\n",
              "      <th>Hydroxyproline (mg)</th>\n",
              "      <th>Alcohol (g)</th>\n",
              "      <th>Caffeine (mg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>inf_0_6m</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>inf_6_12m</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ag1-3</td>\n",
              "      <td>500.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ag4-6</td>\n",
              "      <td>700.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ag7-9</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ag10-12</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ag13-15</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.300</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ag16-17</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.300</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>adlt_lowact</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>2.500</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>adlt_medact</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>0.050</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>adlt_highact</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>3.250</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>pregn_3-6</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>3.250</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>preg_6-9</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>3.250</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lact</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>3.250</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>brkfst_dnnr</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lunch</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>snaks</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>wholeday</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>keto_50_30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>rat_60_carb</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>frsh_vegan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>diabet</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>non_veg_cntrl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>maditer_cntrl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>normal_cntrl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>freeof_cntrl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>micro_vit_cntrl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31 rows × 102 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0700ea93-b43f-44d0-a53d-64fb890649d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0700ea93-b43f-44d0-a53d-64fb890649d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0700ea93-b43f-44d0-a53d-64fb890649d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6311bf81-95d6-4246-b162-a794b15266a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6311bf81-95d6-4246-b162-a794b15266a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6311bf81-95d6-4246-b162-a794b15266a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0a27294c-38c4-45e3-80ca-2c71ea447c14\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('inp_spec')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0a27294c-38c4-45e3-80ca-2c71ea447c14 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('inp_spec');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Unnamed: 0  total_qty_max  Cereal  Vegetables   nuts  pulses  dairy  \\\n",
              "0          inf_0_6m          200.0   0.200       0.200  0.100   0.200  0.100   \n",
              "1         inf_6_12m          250.0   0.400       0.400  0.200   0.400  0.200   \n",
              "2             ag1-3          500.0   0.400       0.400  0.100   0.400  0.400   \n",
              "3             ag4-6          700.0   0.400       0.400  0.100   0.400  0.400   \n",
              "4             ag7-9          800.0   0.400       0.400  0.100   0.400  0.400   \n",
              "5           ag10-12         1000.0   0.500       0.500  0.100   0.500  0.500   \n",
              "6           ag13-15         1200.0   0.500       0.500  0.100   0.500  0.500   \n",
              "7           ag16-17         1200.0   0.500       0.500  0.100   0.500  0.500   \n",
              "8       adlt_lowact         1500.0   2.500       2.000  0.100   0.500  1.000   \n",
              "9       adlt_medact         1500.0   0.050       2.000  0.400   0.900  1.000   \n",
              "10     adlt_highact         1500.0   3.250       2.000  0.400   0.900  1.000   \n",
              "11        pregn_3-6         1500.0   3.250       2.000  0.400   0.900  1.000   \n",
              "12         preg_6-9         1500.0   3.250       2.000  0.400   0.900  1.000   \n",
              "13             lact         1500.0   3.250       2.000  0.400   0.900  1.000   \n",
              "14      brkfst_dnnr            0.3   0.003       0.003  0.003   0.003  0.003   \n",
              "15            lunch            0.3   0.003       0.003  0.003   0.003  0.003   \n",
              "16            snaks            0.1   0.001       0.001  0.001   0.001  0.001   \n",
              "17         wholeday            1.0   0.010       0.010  0.010   0.010  0.010   \n",
              "18       keto_50_30            1.0   0.010       0.010  0.010   0.012  0.010   \n",
              "19      rat_60_carb            1.0   0.010       0.010  0.010   0.010  0.010   \n",
              "20       frsh_vegan            1.0   0.010       0.010  0.010   0.010  0.010   \n",
              "21           diabet            1.0   0.010       0.010  0.000   0.010  0.005   \n",
              "22    non_veg_cntrl            1.0   0.000       0.000  0.000   0.000  0.000   \n",
              "23    maditer_cntrl            1.0   0.010       0.010  0.000   0.010  0.010   \n",
              "24     normal_cntrl            1.0   0.010       0.010  0.000   0.000  0.000   \n",
              "25     freeof_cntrl            1.0   0.000       0.000  0.000   0.000  0.000   \n",
              "26  micro_vit_cntrl            1.0   0.000       0.000  0.000   0.000  0.000   \n",
              "27                0            0.0   0.000       0.000  0.000   0.000  0.000   \n",
              "28                0            0.0   0.000       0.000  0.000   0.000  0.000   \n",
              "29                0            0.0   0.000       0.000  0.000   0.000  0.000   \n",
              "30                0            0.0   0.000       0.000  0.000   0.000  0.000   \n",
              "\n",
              "    non-veg  processd  Calories  ...  Histidine (mg)  Alanine (mg)  \\\n",
              "0     0.000     0.000      92.0  ...             0.0           0.0   \n",
              "1     0.000     0.000     100.0  ...             0.0           0.0   \n",
              "2     0.000     0.100    1000.0  ...             0.0           0.0   \n",
              "3     0.300     0.200    1200.0  ...             0.0           0.0   \n",
              "4     0.300     0.300    1500.0  ...             0.0           0.0   \n",
              "5     0.300     0.300    1900.0  ...             0.0           0.0   \n",
              "6     0.300     0.300    2300.0  ...             0.0           0.0   \n",
              "7     0.300     0.300    2500.0  ...             0.0           0.0   \n",
              "8     1.000     0.100    1300.0  ...             0.0           0.0   \n",
              "9     2.000     0.100    1700.0  ...             0.0           0.0   \n",
              "10    2.000     0.100    2020.0  ...             0.0           0.0   \n",
              "11    2.000     0.100    1700.0  ...             0.0           0.0   \n",
              "12    2.000     0.100    2020.0  ...             0.0           0.0   \n",
              "13    2.000     0.100    1700.0  ...             0.0           0.0   \n",
              "14    0.003     0.003       0.3  ...             0.0           0.0   \n",
              "15    0.003     0.003       0.3  ...             0.0           0.0   \n",
              "16    0.001     0.001       0.1  ...             0.0           0.0   \n",
              "17    0.010     0.010       1.0  ...             0.0           0.0   \n",
              "18    0.012     0.000       1.0  ...             0.0           0.0   \n",
              "19    0.010     0.000       1.0  ...             0.0           0.0   \n",
              "20    0.000     0.000       1.0  ...             0.0           0.0   \n",
              "21    0.000     0.000       0.9  ...             0.0           0.0   \n",
              "22    0.010     0.000       1.0  ...             0.0           0.0   \n",
              "23    0.000     0.010       1.0  ...             0.0           0.0   \n",
              "24    0.000     0.010       1.0  ...             0.0           0.0   \n",
              "25    0.000     0.000       1.0  ...             0.0           0.0   \n",
              "26    0.000     0.010       1.0  ...             0.0           0.0   \n",
              "27    0.000     0.000       0.0  ...             0.0           0.0   \n",
              "28    0.000     0.000       0.0  ...             0.0           0.0   \n",
              "29    0.000     0.000       0.0  ...             0.0           0.0   \n",
              "30    0.000     0.000       0.0  ...             0.0           0.0   \n",
              "\n",
              "    Aspartic acid (mg)  Glutamic acid (mg)  Glycine (mg)  Proline (mg)  \\\n",
              "0                  0.0                 0.0           0.0           0.0   \n",
              "1                  0.0                 0.0           0.0           0.0   \n",
              "2                  0.0                 0.0           0.0           0.0   \n",
              "3                  0.0                 0.0           0.0           0.0   \n",
              "4                  0.0                 0.0           0.0           0.0   \n",
              "5                  0.0                 0.0           0.0           0.0   \n",
              "6                  0.0                 0.0           0.0           0.0   \n",
              "7                  0.0                 0.0           0.0           0.0   \n",
              "8                  0.0                 0.0           0.0           0.0   \n",
              "9                  0.0                 0.0           0.0           0.0   \n",
              "10                 0.0                 0.0           0.0           0.0   \n",
              "11                 0.0                 0.0           0.0           0.0   \n",
              "12                 0.0                 0.0           0.0           0.0   \n",
              "13                 0.0                 0.0           0.0           0.0   \n",
              "14                 0.0                 0.0           0.0           0.0   \n",
              "15                 0.0                 0.0           0.0           0.0   \n",
              "16                 0.0                 0.0           0.0           0.0   \n",
              "17                 0.0                 0.0           0.0           0.0   \n",
              "18                 0.0                 0.0           0.0           0.0   \n",
              "19                 0.0                 0.0           0.0           0.0   \n",
              "20                 0.0                 0.0           0.0           0.0   \n",
              "21                 0.0                 0.0           0.0           0.0   \n",
              "22                 0.0                 0.0           0.0           0.0   \n",
              "23                 0.0                 0.0           0.0           0.0   \n",
              "24                 0.0                 0.0           0.0           0.0   \n",
              "25                 0.0                 0.0           0.0           0.0   \n",
              "26                 0.0                 0.0           0.0           0.0   \n",
              "27                 0.0                 0.0           0.0           0.0   \n",
              "28                 0.0                 0.0           0.0           0.0   \n",
              "29                 0.0                 0.0           0.0           0.0   \n",
              "30                 0.0                 0.0           0.0           0.0   \n",
              "\n",
              "    Serine (mg)  Hydroxyproline (mg)  Alcohol (g)  Caffeine (mg)  \n",
              "0           0.0                  0.0          0.0            0.0  \n",
              "1           0.0                  0.0          0.0            0.0  \n",
              "2           0.0                  0.0          0.0            0.0  \n",
              "3           0.0                  0.0          0.0            0.0  \n",
              "4           0.0                  0.0          0.0            0.0  \n",
              "5           0.0                  0.0          0.0            0.0  \n",
              "6           0.0                  0.0          0.0            0.0  \n",
              "7           0.0                  0.0          0.0            0.0  \n",
              "8           0.0                  0.0          0.0            0.0  \n",
              "9           0.0                  0.0          0.0            0.0  \n",
              "10          0.0                  0.0          0.0            0.0  \n",
              "11          0.0                  0.0          0.0            0.0  \n",
              "12          0.0                  0.0          0.0            0.0  \n",
              "13          0.0                  0.0          0.0            0.0  \n",
              "14          0.0                  0.0          0.0            0.0  \n",
              "15          0.0                  0.0          0.0            0.0  \n",
              "16          0.0                  0.0          0.0            0.0  \n",
              "17          0.0                  0.0          0.0            0.0  \n",
              "18          0.0                  0.0          0.0            0.0  \n",
              "19          0.0                  0.0          0.0            0.0  \n",
              "20          0.0                  0.0          0.0            0.0  \n",
              "21          0.0                  0.0          0.0            0.0  \n",
              "22          0.0                  0.0          0.0            0.0  \n",
              "23          0.0                  0.0          0.0            0.0  \n",
              "24          0.0                  0.0          0.0            0.0  \n",
              "25          0.0                  0.0          0.0            0.0  \n",
              "26          0.0                  0.0          0.0            0.0  \n",
              "27          0.0                  0.0          0.0            0.0  \n",
              "28          0.0                  0.0          0.0            0.0  \n",
              "29          0.0                  0.0          0.0            0.0  \n",
              "30          0.0                  0.0          0.0            0.0  \n",
              "\n",
              "[31 rows x 102 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_spec = pd.read_csv(\"/content/drive/MyDrive/DietApp/Fooddata/nutri_req_cntrls.csv\")\n",
        "inp_spec = inp_spec.fillna(0)\n",
        "inp_spec['Cereal'] = inp_spec['Cereal']/100\n",
        "inp_spec['Vegetables'] = inp_spec['Vegetables']/100 ; inp_spec['nuts'] = inp_spec['nuts']/100 ; inp_spec['pulses'] = inp_spec['pulses']/100\n",
        "inp_spec['dairy'] = inp_spec['dairy']/100 ; inp_spec['non-veg'] = inp_spec['non-veg']/100 ; inp_spec['processd'] = inp_spec['processd']/100\n",
        "inp_qry = inp_spec.drop(['Unnamed: 0','total_qty_max'], axis=1)\n",
        "inp_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoxd_WkbD0UP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_u3rply3E9h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcyCNEnK3Ff1"
      },
      "source": [
        "Query to emb,target and mask mapping\n",
        "\n",
        "0. age13-15 wholeday norm_cntrl\n",
        "1. age16-17 wholeday norm_cntrl\n",
        "2. adlt_lowact wholeday norm_cntrl\n",
        "3. adlt_hghact wholeday norm_cntrl\n",
        "4. age13-15 lunch norm_cntrl\n",
        "5. age16-17 lunch norm_cntrl\n",
        "6. adlt_lowact lunch norm_cntrl\n",
        "7. adlt_hghact lunch norm_cntrl\n",
        "8. age13-15 wholeday free_cntrl\n",
        "9. age16-17 wholeday free_cntrl\n",
        "10. adlt_lowact wholeday free_cntrl\n",
        "11. adlt_hghact wholeday free_cntrl\n",
        "12. age13-15 lunch free_cntrl\n",
        "13. age16-17 lunch free_cntrl\n",
        "14. adlt_lowact lunch free_cntrl\n",
        "15. adlt_hghact lunch free_cntrl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBHkfpvIRRWY",
        "outputId": "42cae8c2-fb23-4ef9-87a9-004ea0e34d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.25e+00 2.00e+00 4.00e-01 9.00e-01 1.00e+00 2.00e+00 1.00e-01 2.02e+03\n",
            " 3.00e+01 7.50e+01 3.35e+02 0.00e+00 0.00e+00 2.00e+00 0.00e+00 5.00e+02\n",
            " 3.00e+01 0.00e+00 0.00e+00 0.00e+00 7.70e+02 1.20e+02 5.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 1.00e+01 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n"
          ]
        }
      ],
      "source": [
        "inp=3;\n",
        "if inp < 8 :\n",
        "  out_mask = np.array(inp_qry.iloc[24].values)\n",
        "else:\n",
        "  out_mask = np.array(inp_qry.iloc[25].values)\n",
        "if inp % 4 == 0 :\n",
        "  age = np.array(inp_qry.iloc[6].values)\n",
        "elif inp % 4 == 1 :\n",
        "  age = np.array(inp_qry.iloc[7].values)\n",
        "elif inp%4 ==2:\n",
        "  age = np.array(inp_qry.iloc[8].values)\n",
        "else :\n",
        "  age = np.array(inp_qry.iloc[10].values)\n",
        "if inp % 7 < 4:\n",
        "  lnch = np.array(inp_qry.iloc[15].values); print(age)\n",
        "  tar = age * lnch * out_mask\n",
        "else:\n",
        "  tar = age * out_mask\n",
        "\n",
        "def map_tarmsk(inp):\n",
        "  if inp < 8 :\n",
        "    out_mask = np.array(inp_qry.iloc[24].values)\n",
        "  else:\n",
        "    out_mask = np.array(inp_qry.iloc[25].values)\n",
        "  if inp % 4 == 0 :\n",
        "    age = np.array(inp_qry.iloc[6].values)\n",
        "  elif inp % 4 == 1 :\n",
        "    age = np.array(inp_qry.iloc[7].values)\n",
        "  elif inp%4 ==2:\n",
        "    age = np.array(inp_qry.iloc[8].values)\n",
        "  else :\n",
        "    age = np.array(inp_qry.iloc[10].values)\n",
        "  if inp % 7 < 4:\n",
        "    lnch = np.array(inp_qry.iloc[15].values)\n",
        "    tar = age * lnch * out_mask\n",
        "  else:\n",
        "    tar = age * out_mask\n",
        "  tar = np.reshape(tar,(1,100))\n",
        "  out_mask = np.reshape(out_mask,(1,100))\n",
        "  return tar, out_mask\n",
        "\n",
        "def pos_enc(pos, dim, n=10000):\n",
        "  p = np.zeros((1,dim))\n",
        "  for i in np.arange(int(dim/2)):\n",
        "    den = np.power(n,2*i/dim)\n",
        "    p[0,2*i] = np.sin(pos/den)\n",
        "    p[0,2*i+1] = np.cos(pos/den)\n",
        "    return p\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFBaCUxoOnwt"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "train data set preparation\n",
        "\n",
        "input spec -- encoding\n",
        "\n",
        "food data -- norm + pos encoding\n",
        "\n",
        "target spec\n",
        "\n",
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Mf9eaqOnGJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "pos_enc_df_3000 = pd.DataFrame()\n",
        "dim=100\n",
        "for i in range(3000):\n",
        "  pos_enc_df_3000.iloc[i] = pos_enc(i, dim)\n",
        "pos_enc.to_csv('/content/drive/MyDrive/DietApp/Fooddata/posencoding/pos_snc_df_3000_dim_100.csv')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR9nveue8xp3",
        "outputId": "f2972e47-c3a8-459b-a6e4-43204f989a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(320, 4, 100)\n",
            "(320, 500, 100)\n"
          ]
        }
      ],
      "source": [
        "btch = 320 ;  dim=100; key_len=500;  out_len=4\n",
        "\n",
        "inp_seq = np.random.randint(0,high=16,size=(btch))\n",
        "inp_seq_emb = tf.keras.layers.Embedding(input_dim=16,output_dim=dim)(inp_seq)\n",
        "inp_seq_emb = tf.expand_dims(inp_seq_emb,axis=1)\n",
        "inp_pos_btch = np.random.randint(0,high=4,size=(btch))\n",
        "inp_pos_emb = tf.keras.layers.Embedding(input_dim=5,output_dim=out_len)(inp_pos_btch)\n",
        "#inp_pos_emb = keras_nlp.layers.SinePositionEncoding()(np.zeros((btch,out_len)))\n",
        "inp_pos_emb = np.random.rand(btch,out_len) * np.random.randint(0,10,size=(btch,out_len)) ; inp_pos_emb = inp_pos_emb.astype(np.float32)\n",
        "inp_pos_emb = tf.expand_dims(inp_pos_emb,axis=-1)\n",
        "pos_enc = tf.matmul(inp_pos_emb,inp_seq_emb)\n",
        "inp_x = tf.math.add(inp_seq_emb,pos_enc)  # shape(btch,out_len,dim)\n",
        "print(inp_x.shape)\n",
        "\n",
        "key_pos_emb = keras_nlp.layers.SinePositionEncoding()(np.zeros((btch,key_len)))\n",
        "key_pos_emb = tf.expand_dims(key_pos_emb, axis=-1)\n",
        "key_pos = key_pos_emb * np.ones((btch,key_len,dim)) ; key_pos = tf.cast(key_pos,dtype=tf.float32)\n",
        "\n",
        "kys = tf.expand_dims(usda_clstr,axis=0 ) ; kys = kys+np.zeros((btch,key_len,dim)); print(kys.shape)\n",
        "kys = tf.cast(kys, tf.float32)\n",
        "#kys = tf.math.add(kys , 0.5*key_pos)  ;\n",
        "kys_norm = tf.keras.layers.BatchNormalization()(kys)\n",
        "\n",
        "targt_y = np.zeros((btch,1,dim))\n",
        "out_msk = np.zeros((btch,1,dim))\n",
        "for i in range(btch):\n",
        "  targt_y[i,0,:], out_msk[i,0,:] = map_tarmsk(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csu0cSI8Yjbu",
        "outputId": "cf12cc63-824e-4c03-fe2b-e1d92a3aa374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([-0.00236504  0.01907114 -0.00523492  0.04349214], shape=(4,), dtype=float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "       [ 0.84147096,  0.5403023 ,  0.00999983,  0.99995   ],\n",
              "       [ 0.9092974 , -0.41614684,  0.01999867,  0.9998    ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " print(tf.keras.layers.Embedding(input_dim=15,output_dim=4)(3))\n",
        " keras_nlp.layers.SinePositionEncoding()(np.zeros((3,4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Oyq0j4p9Liq",
        "outputId": "45af9a6c-3d76-4800-e68d-6be75d70bd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(320, 4, 100)\n",
            "(320, 4, 100)\n"
          ]
        }
      ],
      "source": [
        "btch = 320 ;  dim=100; key_len=500;  out_len=4\n",
        "\n",
        "inp_seq1 = np.random.randint(0,high=16,size=(btch))\n",
        "inp_seq_emb1 = tf.keras.layers.Embedding(input_dim=16,output_dim=dim)(inp_seq1)\n",
        "inp_seq_emb1 = tf.expand_dims(inp_seq_emb1,axis=1)\n",
        "inp_pos_btch1 = np.random.randint(0,high=5,size=(btch))\n",
        "inp_pos_emb1 = tf.keras.layers.Embedding(input_dim=5,output_dim=out_len)(inp_pos_btch1)\n",
        "inp_pos_emb1 = tf.expand_dims(inp_pos_emb1,axis=-1)\n",
        "pos_enc1 = tf.matmul(inp_pos_emb1,inp_seq_emb1)\n",
        "inp_x1 = tf.math.add(inp_seq_emb1,pos_enc1)  # shape(btch,out_len,dim)\n",
        "print(inp_x1.shape)\n",
        "\n",
        "targt_y1 = np.zeros((btch,1,dim))\n",
        "out_msk1 = np.zeros((btch,1,dim))\n",
        "for i in range(btch):\n",
        "  targt_y1[i,0,:], out_msk1[i,0,:] = map_tarmsk(i)\n",
        "\n",
        "inp_seq2 = np.random.randint(0,high=16,size=(btch))\n",
        "inp_seq_emb2 = tf.keras.layers.Embedding(input_dim=16,output_dim=dim)(inp_seq2)\n",
        "inp_seq_emb2 = tf.expand_dims(inp_seq_emb2,axis=1)\n",
        "inp_pos_btch2 = np.random.randint(0,high=5,size=(btch))\n",
        "inp_pos_emb2 = tf.keras.layers.Embedding(input_dim=5,output_dim=out_len)(inp_pos_btch2)\n",
        "inp_pos_emb2 = tf.expand_dims(inp_pos_emb2,axis=-1)\n",
        "pos_enc2 = tf.matmul(inp_pos_emb2,inp_seq_emb1)\n",
        "inp_x2 = tf.math.add(inp_seq_emb2,pos_enc2)  # shape(btch,out_len,dim)\n",
        "print(inp_x2.shape)\n",
        "\n",
        "targt_y2 = np.zeros((btch,1,dim))\n",
        "out_msk2 = np.zeros((btch,1,dim))\n",
        "for i in range(btch):\n",
        "  targt_y2[i,0,:], out_msk2[i,0,:] = map_tarmsk(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XBUBavTXyc_6",
        "outputId": "40e782f9-8a7a-420a-a2da-b17003fe9cd9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nkysnrm= Normalizer()\\nkys_norm = tf.keras.layers.BatchNormalization()(kys)\\ntarnrm = Normalizer()\\ntargt_y = tf.keras.layers.BatchNormalization()(targt_y)\\ntargt_y1 = tf.keras.layers.BatchNormalization()(targt_y1)\\ntargt_y2 = tf.keras.layers.BatchNormalization()(targt_y2)\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "kys = tf.cast(kys,tf.float32)\n",
        "targt_y = tf.cast(targt_y, tf.float32)\n",
        "targt_y1 = tf.cast(targt_y1, tf.float32)\n",
        "targt_y2 = tf.cast(targt_y2, tf.float32)\n",
        "targt_y\n",
        "\n",
        "\"\"\"\n",
        "kysnrm= Normalizer()\n",
        "kys_norm = tf.keras.layers.BatchNormalization()(kys)\n",
        "tarnrm = Normalizer()\n",
        "targt_y = tf.keras.layers.BatchNormalization()(targt_y)\n",
        "targt_y1 = tf.keras.layers.BatchNormalization()(targt_y1)\n",
        "targt_y2 = tf.keras.layers.BatchNormalization()(targt_y2)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7chW6e3o0Nf"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqidkXcNo2t-"
      },
      "outputs": [],
      "source": [
        "out_seq = np.ones((btch,out_len,dim))\n",
        "\n",
        "def get_loss(out_seq,msk,targt):\n",
        "  out = tf.math.reduce_sum(out_seq,axis=1,keep_dim=True)\n",
        "  out = out * msk\n",
        "  loss_norm = out - targt / 25\n",
        "  return loss_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJsqfRUByZzs"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5mDAuIpydDT"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANVF6Kqv08ka"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    # Shape `(batch_size, seq_len, d_model)\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7WNgLHh12dm"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x, self.last_attn_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIrp87rH9Lis",
        "outputId": "fe8628cd-cde7-4ff3-fda7-db8f835c77b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[1. 2.]\n",
            "  [2. 3.]\n",
            "  [3. 1.]]], shape=(1, 3, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.09003057 0.24472848]\n",
            "  [0.24472848 0.6652409 ]\n",
            "  [0.6652409  0.09003057]]], shape=(1, 3, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "arry = tf.constant([[[1.0,2.0],[2.0,3],[3,1]]])\n",
        "ansre = tf.keras.activations.softmax(arry,axis=-2)\n",
        "print(arry)\n",
        "print(ansre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbQA7gt76AFA"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    self.sing_head = DecoderLayer(d_model=d_model, num_heads=1,dff=dff, dropout_rate=dropout_rate)\n",
        "    self.dens =  tf.keras.layers.Dense(200, activation='relu')\n",
        "    self.dens_fnl =  tf.keras.layers.Dense(1,activation='tanh')\n",
        "    self.dpt_conv = tf.keras.layers.Conv1D(4,50,strides=1,activation='tanh')\n",
        "    self.btch_norm = tf.keras.layers.BatchNormalization(); self.btch_norm1 = tf.keras.layers.BatchNormalization(); self.btch_norm2 = tf.keras.layers.BatchNormalization()\n",
        "    self.cal_msk = np.zeros((1,100)) ; self.cal_msk[0,7:15] = 1; self.cal_msk = tf.convert_to_tensor(self.cal_msk,dtype=tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x1  = inputs\n",
        "\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x, attn_scrs = self.decoder(x1, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    \"\"\"add another decoder one one head attention\"\"\"\n",
        "    x = self.sing_head(x,context)\n",
        "    attn_scrs = self.sing_head.last_attn_scores\n",
        "\n",
        "    # Final linear layer output.\n",
        "    # logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    #for 4 dsh wgts\n",
        "    logits = tf.transpose(tf.squeeze(attn_scrs,axis=1),perm=[0,2,1])\n",
        "\n",
        "    logits = tf.keras.activations.softmax(logits,axis=1)\n",
        "    logits = tf.matmul(logits,x1)\n",
        "    logits = tf.math.multiply(logits, self.cal_msk)\n",
        "    logits = tf.keras.layers.Concatenate()([logits,context])\n",
        "    logits = self.btch_norm(logits)\n",
        "    logits = self.dpt_conv(tf.transpose(logits,perm=[0,2,1]))\n",
        "    logits = self.btch_norm1(logits)\n",
        "    logits = self.dens(tf.transpose(logits,perm=[0,2,1]))\n",
        "    logits = self.btch_norm2(logits)\n",
        "    logits = self.dens_fnl(logits)\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits, x, attn_scrs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pui1eWZNBZDU"
      },
      "source": [
        "Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcWYEWngBYes"
      },
      "outputs": [],
      "source": [
        "qry_len = 4; key_len =500 ; dim=100;\n",
        "num_heads= 10   ; num_layers=1 ;\n",
        "\n",
        "mdl = Transformer( num_layers=3, d_model=dim, num_heads=10, dff=100,\n",
        "               input_vocab_size=100, target_vocab_size=1, dropout_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqCSpVAQTCqG",
        "outputId": "78a13c33-62db-4a78-8044-b6ee78638e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 4, 1) (32, 500, 100) (32, 1, 500, 4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "inp = tf.expand_dims(inp_x[:32,:,:],axis=1) ;  ky = tf.expand_dims(kys[:32,:,:],axis=1)\n",
        "out,x ,att = mdl([inp_x[:32,:,:],kys_norm[:32,:,:]])\n",
        "print(out.shape,x.shape,att.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7fp0tEHyeAt"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLc9RElFsahB"
      },
      "outputs": [],
      "source": [
        "def get_norm_loss(out_seq,msk,targt):\n",
        "  out = tf.math.reduce_sum(out_seq,axis=1,keepdims=True)\n",
        "  out = tf.math.multiply(out , msk)\n",
        "  targt = tf.math.multiply(targt,msk)\n",
        "  loss_norm = (out - targt) / 25 ; loss_norm = tf.math.abs(loss_norm)\n",
        "\n",
        "  cal_msk = np.zeros((1,100)); cal_msk[0,7]=1\n",
        "  cal_loss = tf.multiply(loss_norm,cal_msk)\n",
        "  loss_sig = 1 - tf.keras.activations.sigmoid(out-targt)\n",
        "  sig_mask = np.ones((1,100)) ; sig_mask[0,0:7] = 0.5 ; # sig_mask[0,10:16] = 0.5 ;\n",
        "  sig_loss = tf.multiply(loss_sig,sig_mask)\n",
        "  loss_tot = cal_loss + loss_sig\n",
        "  return loss_tot\n",
        "\n",
        "class tfrmr(tf.keras.Model):\n",
        "    def __init__(self,mdl,qry,kys_norm,out_msk,targt,los,opt,tbl):\n",
        "        super().__init__()\n",
        "        self.mdl = mdl;\n",
        "        self.qry = qry\n",
        "        self.kys = kys_norm\n",
        "        self.out_msk = out_msk\n",
        "        self.targt = targt\n",
        "        self.los=los;\n",
        "        self.opt= opt;\n",
        "        self.tbl= tbl\n",
        "        #print(self.qry.shape, self.kys.shape, self.out_msk.shape, self.targt.shape, self.tbl.shape)\n",
        "\n",
        "    def compile(self,loss,opt,metrics):\n",
        "        super().compile()\n",
        "        self.mdl.compile(loss=self.los,optimizer=self.opt,metrics=[\"Accuracy\"])\n",
        "    def train_step(self,inp):\n",
        "\n",
        "        batch=32 ; loss=0 ; num_btch=1\n",
        "        #qryitr = iter(self.qry) ; taritr = iter(self.targt)\n",
        "        for i in range(num_btch):\n",
        "            kys = self.kys[0:batch, :,:] ; out_msk = self.out_msk ; tbl = self.tbl[0:batch,:,:] ;\n",
        "            qry = self.qry[i*batch: i*batch+batch,: ,:] ; targt = self.targt[i*batch:i*batch+batch,: ,:]\n",
        "            with tf.GradientTape() as grdtp:\n",
        "                grdtp.watch(self.mdl.trainable_variables)\n",
        "                out_wgt, x, attn_scr = self.mdl([qry, kys])\n",
        "                out = tf.math.argmax(attn_scr, axis=-2)\n",
        "                out = tf.one_hot(out,500,axis=-1)\n",
        "                out = tf.squeeze(out)\n",
        "                #k = tf.transpose(self.kys,[0,2,1])\n",
        "                out_seq = tf.matmul(out,tbl)\n",
        "                out_seq = out_seq * out_wgt *2.5\n",
        "                lss = self.los(out_seq,out_msk,targt)\n",
        "                loss = loss+lss\n",
        "                #cos_los = tf.keras.losses.cosine_similarity(self.rel,fke)\n",
        "                #lss_tot = 10*tf.keras.losses.mean_absolute_error(self.rel,fke) +1.5*(1+cos_los)**2\n",
        "                if i < num_btch-1 :\n",
        "                  continue\n",
        "                loss = loss/num_btch\n",
        "                grd = grdtp.gradient(loss,self.mdl.trainable_variables)\n",
        "            self.opt.apply_gradients(zip(grd,self.mdl.trainable_variables))\n",
        "            \"\"\"\n",
        "            with tf.GradientTape() as grdtp:\n",
        "                grdtp.watch(self.mdl.trainable_variables)\n",
        "                out_wgt, x, attn_scr = self.mdl([inp_x1,self.kys ])\n",
        "                out = tf.math.argmax(attn_scr, axis=-2)\n",
        "                out = tf.one_hot(out,500,axis=-1)\n",
        "                out = tf.squeeze(out)\n",
        "                #k = tf.transpose(self.kys,[0,2,1])\n",
        "                out_seq = tf.matmul(out,self.tbl)\n",
        "                out_seq = out_seq * out_wgt *2\n",
        "                lss1 = self.los(out_seq,out_msk1,targt_y1)\n",
        "                #cos_los = tf.keras.losses.cosine_similarity(self.rel,fke)\n",
        "                #lss_tot = 10*tf.keras.losses.mean_absolute_error(self.rel,fke) +1.5*(1+cos_los)**2\n",
        "\n",
        "                grd = grdtp.gradient(lss1,self.mdl.trainable_variables)\n",
        "\n",
        "            self.opt.apply_gradients(zip(grd,self.mdl.trainable_variables))\n",
        "\n",
        "            with tf.GradientTape() as grdtp:\n",
        "                grdtp.watch(self.mdl.trainable_variables)\n",
        "                out_wgt, x, attn_scr = self.mdl([inp_x2, self.kys ])\n",
        "                out = tf.math.argmax(attn_scr, axis=-2)\n",
        "                out = tf.one_hot(out,500,axis=-1)\n",
        "                out = tf.squeeze(out)\n",
        "                #k = tf.transpose(self.kys,[0,2,1])\n",
        "                out_seq = tf.matmul(out,self.tbl)\n",
        "                out_seq = out_seq * out_wgt *2\n",
        "                lss1 = self.los(out_seq,out_msk2,targt_y2)\n",
        "                #cos_los = tf.keras.losses.cosine_similarity(self.rel,fke)\n",
        "                #lss_tot = 10*tf.keras.losses.mean_absolute_error(self.rel,fke) +1.5*(1+cos_los)**2\n",
        "\n",
        "                grd = grdtp.gradient(lss1,self.mdl.trainable_variables)\n",
        "\n",
        "            self.opt.apply_gradients(zip(grd,self.mdl.trainable_variables)) \"\"\"\n",
        "\n",
        "        return {\"loss\":loss }\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkefZ165ySpo",
        "outputId": "36e68ef4-984a-4a0c-da3c-f3d36ca61dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/bias:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/bias:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/gamma:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/beta:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/gamma:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/bias:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/bias:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/gamma:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/beta:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/gamma:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/bias:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/bias:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/gamma:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/beta:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/gamma:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/value/bias:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/kernel:0', 'transformer/decoder_layer_3/cross_attention_3/multi_head_attention_10/attention_output/bias:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/gamma:0', 'transformer/decoder_layer_3/cross_attention_3/layer_normalization_16/beta:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/gamma:0', 'transformer/decoder_layer_3/feed_forward_6/layer_normalization_17/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "320/320 [==============================] - 3999s 12s/step - loss: 0.6761\n",
            "Epoch 2/3\n",
            "320/320 [==============================] - 3977s 12s/step - loss: 0.6149\n",
            "Epoch 3/3\n",
            " 78/320 [======>.......................] - ETA: 50:08 - loss: 0.5891"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.00001)\n",
        "#targt_y = tf.data.Dataset.from_tensors(targt_y) ; inp_x = tf.data.Dataset.from_tensors(inp_x)\n",
        "dta = tf.data.Dataset.from_tensor_slices((inp_x,targt_y)) ;\n",
        "trng = tfrmr(mdl,inp_x,kys_norm,out_mask,targt_y,get_norm_loss,opt,kys)\n",
        "trng.compile(get_norm_loss,opt,['Accuracy'])\n",
        "hist = trng.fit(dta, epochs=3, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zojtg4B0cf2c",
        "outputId": "3a3fca2d-dc5e-4823-c66c-916a9aabd974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7811\n",
            "Epoch 2/2\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7824\n"
          ]
        }
      ],
      "source": [
        "hist = trng.fit(inp_x, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CBYABJBySmC",
        "outputId": "2a0f26a3-f343-4a70-d7a6-c044a71c3fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/gamma:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/beta:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/gamma:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/gamma:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/beta:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/gamma:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/gamma:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/beta:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/gamma:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/value/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/kernel:0', 'transformer_12/decoder_layer_39/cross_attention_39/multi_head_attention_106/attention_output/bias:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/gamma:0', 'transformer_12/decoder_layer_39/cross_attention_39/layer_normalization_172/beta:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/gamma:0', 'transformer_12/decoder_layer_39/feed_forward_66/layer_normalization_173/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 48s 1s/step - loss: 0.7833\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7843\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7846\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7862\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.7845\n"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.000001)\n",
        "trng = tfrmr(mdl,inp_x,kys_norm,out_mask,targt_y,get_norm_loss,opt,kys)\n",
        "trng.compile(get_norm_loss,opt,['Accuracy'])\n",
        "hist = trng.fit(inp_x, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDxg_G0nDa7M"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJKdPfDJDZvi",
        "outputId": "a2c17878-de77-4adc-e609-88b840c67f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[174 443 443 174]]\n",
            "\n",
            " [[436 439 201 353]]\n",
            "\n",
            " [[455 496 455 496]]\n",
            "\n",
            " [[ 44 174 443 429]]\n",
            "\n",
            " [[144 201 144 144]]], shape=(5, 1, 4), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[[0.49769044]\n",
            "  [0.33997673]\n",
            "  [0.39708725]\n",
            "  [0.08886725]]\n",
            "\n",
            " [[0.23031364]\n",
            "  [0.6138173 ]\n",
            "  [0.07017171]\n",
            "  [0.7975638 ]]\n",
            "\n",
            " [[0.6935474 ]\n",
            "  [0.8106002 ]\n",
            "  [0.73747325]\n",
            "  [0.68074363]]\n",
            "\n",
            " [[0.53252727]\n",
            "  [0.43229437]\n",
            "  [0.18844831]\n",
            "  [0.00192475]]\n",
            "\n",
            " [[0.6052524 ]\n",
            "  [0.05927118]\n",
            "  [0.6250216 ]\n",
            "  [0.5523612 ]]], shape=(5, 4, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 5.86557686e-01 0.00000000e+00 7.39324524e+02\n",
            "  7.91085968e+01 6.02981281e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.70762061e+03 1.78829956e+01 5.86557674e+00\n",
            "  9.38492298e-01 1.51331879e+02 8.21180725e+00 7.37063984e+04\n",
            "  2.21119180e+04 7.91852903e+00 1.28456140e+00 1.84265991e+02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.59626617e+01\n",
            "  1.49396885e+04 7.41945007e+02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.65409271e+02 7.03869247e+01 7.44928241e-01\n",
            "  1.40773848e-01 5.51364198e-02 9.32626724e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 9.09164399e-02 1.61303371e-01\n",
            "  2.50753427e+00 1.64236152e+00 1.11445963e-01 0.00000000e+00\n",
            "  3.51934624e+00 0.00000000e+00 3.51934624e+00 3.51934624e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.21119180e+04 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 7.37063965e+03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 3.54020938e+04 1.74523516e+04 0.00000000e+00\n",
            "  5.08426758e+03 8.18197510e+02 8.34806836e+03 7.74256134e+01\n",
            "  2.81547699e+02 2.78614899e+02 5.25555664e+02 4.73938629e+02\n",
            "  1.19657768e+02 0.00000000e+00 3.06769684e+02 2.52806366e+02\n",
            "  3.43722809e+02 3.15568024e+02 1.61889923e+02 0.00000000e+00\n",
            "  6.02981323e+02 7.05042358e+02 2.89172943e+02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 4.91201989e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 7.97563791e-01 0.00000000e+00 4.82158936e+02\n",
            "  3.79373703e+01 1.65311317e+01 1.88605804e+01 1.06733971e+01\n",
            "  1.57708430e+00 1.19864883e+02 1.18193197e+01 2.03340286e+02\n",
            "  7.73744011e+00 5.11605469e+02 5.20027809e+01 3.87117822e+03\n",
            "  1.14599805e+03 6.92537165e+00 7.78268814e+00 3.68501842e-01\n",
            "  1.34573340e+00 0.00000000e+00 1.72834969e+01 3.24734612e+01\n",
            "  4.12217522e+01 9.52863953e+02 2.30313657e-04 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.95766598e-01\n",
            "  0.00000000e+00 2.91589722e+02 2.44120098e+04 1.74548614e+00\n",
            "  6.14866197e-01 4.50609684e-01 4.09064407e+01 1.25066590e+00\n",
            "  0.00000000e+00 0.00000000e+00 4.82186913e-01 6.66161239e-01\n",
            "  4.70768929e+00 1.26520514e+00 2.76129961e-01 0.00000000e+00\n",
            "  8.16450195e+01 0.00000000e+00 8.16450195e+01 8.16450195e+01\n",
            "  2.83445663e+01 1.15156822e-01 1.14268018e+03 3.90731125e+01\n",
            "  0.00000000e+00 3.22102197e+03 9.95736618e+01 0.00000000e+00\n",
            "  3.68501842e-01 1.49703865e+01 3.31679130e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.23287773e+04 1.20168262e+03 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.35705627e+02\n",
            "  4.29416138e+02 5.07111877e+02 8.56971863e+02 7.24716675e+02\n",
            "  2.23903168e+02 1.34868683e+02 4.77901520e+02 3.36804657e+02\n",
            "  5.98780334e+02 5.81565979e+02 2.56678589e+02 5.56196289e+02\n",
            "  1.00108765e+03 1.54303491e+03 5.52406982e+02 4.69289215e+02\n",
            "  4.17918213e+02 0.00000000e+00 0.00000000e+00 9.21254575e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.43102074e+00 0.00000000e+00 9.79246582e+02\n",
            "  5.38019905e+01 3.36906471e+01 8.94722595e+01 1.30939980e+01\n",
            "  1.31238270e+01 3.63479248e+02 6.05943203e+00 9.37133713e+01\n",
            "  1.52245483e+01 1.83998022e+03 1.24126747e+02 1.35085484e+05\n",
            "  4.22818750e+04 0.00000000e+00 1.20921249e+02 0.00000000e+00\n",
            "  1.72035084e+01 0.00000000e+00 7.63484344e+01 1.07425682e+02\n",
            "  2.19943750e+03 1.71288965e+04 1.10188589e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 7.32782959e+02 4.15870483e+02 5.08347416e+00\n",
            "  8.19586086e+00 4.27875161e-01 2.67436638e+01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 6.62146926e-01 3.59722018e+00\n",
            "  2.51367302e+01 1.47395134e+01 1.40587187e+00 0.00000000e+00\n",
            "  5.51797256e+01 0.00000000e+00 5.51797256e+01 5.51797256e+01\n",
            "  5.42849197e+01 0.00000000e+00 4.05250781e+04 2.10786543e+04\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.43102074e+00 3.63887863e+01 0.00000000e+00\n",
            "  0.00000000e+00 1.42486445e+04 1.93985117e+04 7.58441010e+01\n",
            "  1.60274323e+02 2.06066986e+02 5.58098068e+01 3.07669434e+02\n",
            "  1.06181738e+03 1.21922961e+03 2.21378906e+03 2.32254639e+03\n",
            "  9.64507935e+02 0.00000000e+00 1.14052344e+03 9.87404297e+02\n",
            "  1.29507373e+03 1.92901587e+03 1.05752429e+03 1.52689905e+03\n",
            "  0.00000000e+00 4.09128809e+03 1.59845020e+03 9.41611572e+02\n",
            "  1.03176587e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.34732644e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 4.32294369e-01 0.00000000e+00 4.10387939e+02\n",
            "  2.40624962e+01 5.80744839e+00 4.22451324e+01 2.11093807e+01\n",
            "  4.23445459e-03 1.05630176e+03 5.15931988e+00 1.26609697e+01\n",
            "  9.78985131e-01 1.30971939e+02 6.10793877e+00 1.88448301e+04\n",
            "  5.65344922e+03 5.83597374e+00 9.46724713e-01 4.71120758e+01\n",
            "  0.00000000e+00 0.00000000e+00 4.22408981e+01 4.18744278e+01\n",
            "  4.00890894e+03 2.15278900e+02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.35128128e+02 2.04883881e+02 5.50399661e-01\n",
            "  1.03787214e-01 4.14440632e-02 6.87386513e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 6.70056269e-02 1.18880957e-01\n",
            "  1.84805846e+00 1.21042418e+00 8.21359307e-02 0.00000000e+00\n",
            "  2.59376621e+00 0.00000000e+00 2.59376621e+00 2.59376621e+00\n",
            "  0.00000000e+00 0.00000000e+00 5.65344922e+03 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 1.88448315e+03 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 9.51979785e+03 4.86579492e+03 0.00000000e+00\n",
            "  1.29991638e+03 2.71303925e+02 2.26143359e+03 5.70628586e+01\n",
            "  2.07501297e+02 2.05339828e+02 3.87335754e+02 3.49293854e+02\n",
            "  8.81880493e+01 0.00000000e+00 2.26089951e+02 1.86318878e+02\n",
            "  2.53324493e+02 2.32574371e+02 1.19313248e+02 0.00000000e+00\n",
            "  4.44398621e+02 5.19617859e+02 2.13121124e+02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 4.14898209e-02 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.83435303e+02\n",
            "  5.55446815e+01 1.24412708e+01 1.02989922e+02 1.19790173e+01\n",
            "  7.50304890e+00 0.00000000e+00 7.15935516e+00 6.35641556e+01\n",
            "  2.96315861e+00 2.31732764e+03 1.14891441e+02 7.52378601e+02\n",
            "  3.82606354e+01 1.13559868e+02 0.00000000e+00 0.00000000e+00\n",
            "  7.87983990e+00 0.00000000e+00 9.54868622e+01 5.28392363e+00\n",
            "  5.17616150e+02 2.13162285e+04 2.21046761e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.71886826e+01\n",
            "  0.00000000e+00 2.79582642e+02 9.77878174e+02 1.86493218e+00\n",
            "  5.24653792e-01 7.95729101e-01 1.03904557e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 4.25257564e-01 2.41117179e-01\n",
            "  9.37292671e+00 1.63893890e+00 6.88166201e-01 0.00000000e+00\n",
            "  1.18119095e+02 0.00000000e+00 1.18119095e+02 1.18119095e+02\n",
            "  2.67000694e+01 0.00000000e+00 0.00000000e+00 3.92933044e+02\n",
            "  8.91317558e+00 2.95240796e+03 3.53283691e+02 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 3.12490864e+01 0.00000000e+00\n",
            "  0.00000000e+00 2.35970840e+04 2.18267148e+04 5.02703125e+02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.16420221e+00\n",
            "  2.11598091e+01 2.00929279e+01 3.06431980e+01 3.07617397e+01\n",
            "  7.23108339e+00 1.08466253e+01 2.16932507e+01 1.43436241e+01\n",
            "  2.13968945e+01 2.03300133e+01 1.26840315e+01 2.38270130e+01\n",
            "  1.15993690e+02 3.08328644e+02 2.06263695e+01 1.57661324e+01\n",
            "  2.22266903e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00]], shape=(5, 100), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "ky= kys[5:10,:,:] ; inp= inp_x[10:15,:,:];\n",
        "out_wgt, x, attn_scr = mdl([inp, ky])\n",
        "out1 = tf.math.argmax(attn_scr, axis=-2)\n",
        "out = tf.one_hot(out1,500,axis=-1)\n",
        "out = tf.squeeze(out)\n",
        "\n",
        "out_seq = tf.matmul(out,ky)\n",
        "out_seq = out_seq * out_wgt\n",
        "print(out1); print(out_wgt)\n",
        "print(tf.reduce_sum(out_seq,axis=-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7JOlwqF9Uor",
        "outputId": "357310fd-bb87-44e1-815f-a4279bf6dbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input spec:  7\n",
            "meal plan:  Milk Dessert Frozen Milk-Fat Free Chocolate tf.Tensor(0.49769044, shape=(), dtype=float32)  in 100 g\n",
            "Snacks Granola Bars Soft Uncoated Peanut Butter tf.Tensor(0.33997673, shape=(), dtype=float32)  in 100 g\n",
            "Snacks Granola Bars Soft Uncoated Peanut Butter tf.Tensor(0.39708725, shape=(), dtype=float32)  in 100 g\n",
            "input spec:  4\n",
            "meal plan:  Snacks Corn-Based Extruded Onion-Flavor tf.Tensor(0.23031364, shape=(), dtype=float32)  in 100 g\n",
            "Snacks Crisped Rice Bar Chocolate Chip tf.Tensor(0.6138173, shape=(), dtype=float32)  in 100 g\n",
            "Turkey Light Or Dark Meat Smoked Cooked Skin And Bone Removed tf.Tensor(0.070171714, shape=(), dtype=float32)  in 100 g\n",
            "input spec:  12\n",
            "meal plan:  Snacks Rice Cakes Brown Rice Buckwheat tf.Tensor(0.6935474, shape=(), dtype=float32)  in 100 g\n",
            "Schar Gluten-Free Classic White Rolls tf.Tensor(0.8106002, shape=(), dtype=float32)  in 100 g\n",
            "Snacks Rice Cakes Brown Rice Buckwheat tf.Tensor(0.73747325, shape=(), dtype=float32)  in 100 g\n",
            "input spec:  4\n",
            "meal plan:  Snacks Pretzels Hard Confectioners Coating Chocolate-Flavor tf.Tensor(0.53252727, shape=(), dtype=float32)  in 100 g\n",
            "Milk Dessert Frozen Milk-Fat Free Chocolate tf.Tensor(0.43229437, shape=(), dtype=float32)  in 100 g\n",
            "Snacks Granola Bars Soft Uncoated Peanut Butter tf.Tensor(0.18844831, shape=(), dtype=float32)  in 100 g\n",
            "input spec:  7\n",
            "meal plan:  Corned Beef And Potatoes In Tortilla (Apache) tf.Tensor(0.6052524, shape=(), dtype=float32)  in 100 g\n",
            "Turkey Light Or Dark Meat Smoked Cooked Skin And Bone Removed tf.Tensor(0.059271175, shape=(), dtype=float32)  in 100 g\n",
            "Corned Beef And Potatoes In Tortilla (Apache) tf.Tensor(0.6250216, shape=(), dtype=float32)  in 100 g\n"
          ]
        }
      ],
      "source": [
        "usda_lbl = pd.read_csv(r'/content/drive/MyDrive/DietApp/Fooddata/usda_sr_all_foods.csv')\n",
        "ky= kys[10:15,:,:] ; inp= inp_x[10:15,:,:]\n",
        "out_wgt, x, attn_scr = mdl([inp, ky])\n",
        "out1 = tf.math.argmax(attn_scr, axis=-2)\n",
        "#out = tf.one_hot(out1,500,axis=-1)\n",
        "out = tf.squeeze(out1)\n",
        "for i in range(5):\n",
        "  print(\"input spec: \",inp_seq[i])\n",
        "  dsh = tf.get_static_value(out[i,0])\n",
        "  print(\"meal plan: \", usda_lbl.iloc[dsh,1], out_wgt[i,0,0],\" in 100 g\")\n",
        "  print( usda_lbl.iloc[tf.get_static_value(out[i,1]),1], out_wgt[i,1,0],\" in 100 g\")\n",
        "  print( usda_lbl.iloc[tf.get_static_value(out[i,2]),1], out_wgt[i,2,0],\" in 100 g\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2LcDxOp9UcA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLGe2x3yDZsP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCuCtKHsSK8M"
      },
      "outputs": [],
      "source": [
        "arr = tf.constant([[[1,2,3],[2,5,1]],[[1,2,3],[4,1,2]]])\n",
        "print(arr.shape)\n",
        "arm = tf.math.argmax(arr,axis=-1)\n",
        "print(arm)\n",
        "arm = tf.one_hot(arm,3,axis=-1)\n",
        "print(arm.shape)\n",
        "arr = np.ones((2,2,3))  # ((2,3,4))\n",
        "arm = tf.transpose(arm,[0,2,1])\n",
        "print(arm.shape)\n",
        "tf.matmul(arm, arr)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgZ6GvcUGzY0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j26Qcqcm570G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXJRyUa3o3am"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWqcvLouk2Jd"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1,2,3],[4,5,6]])\n",
        "x = np.reshape(x,(2,3,1))\n",
        "y = np.ones((2,3,5))\n",
        "print(x*y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xkpQMkwx5yl"
      },
      "outputs": [],
      "source": [
        "x = np.ones((2,1,5))\n",
        "y = np.ones((2,3,5))\n",
        "tf.math.add(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC2UbemkW2zB"
      },
      "outputs": [],
      "source": [
        "from positional_encodings.tf_encodings import TFPositionalEncoding2D\n",
        "\n",
        "inp_seq = np.array([[[[1,2,3],[1,1,1]],[[1,1,1],[1,1,1]]]])\n",
        "enc = TFPositionalEncoding2D(3)\n",
        "inp_x = enc(inp_seq)\n",
        "print(inp_x)\n",
        "enc = tf.keras.layers.Embedding(input_dim=4,output_dim=4)(inp_seq)\n",
        "pos = keras_nlp.layers.SinePositionEncoding()([[1,2,3]])\n",
        "pos = tf.keras.layers.Embedding(input_dim=50,output_dim=3)(np.array([1,2,3]))\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIApPBh-RRY0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4JFaYpGRRbS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De8xN9AuRReD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRfNOS8ZRRhS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 3397442,
          "sourceId": 7236341,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30626,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}