{"cells":[{"cell_type":"markdown","metadata":{"id":"dyHETBSyjORe"},"source":["# Training VAE on USDA SR legacy food dataset\n","\n","**Author:** [Yoga Harshitha Duddukuri](https://www.linkedin.com/in/dyogaharshitha)<br>\n","\n","**Description:** USDA SR legacy food dataset was cleaned and processed. Encoder in VAE reduces the dimension to 50 , which was originally 100, decoder retrives the data with MAE of 0.07"]},{"cell_type":"markdown","metadata":{"id":"AI_h0sNgjORl"},"source":["## Import modules"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T08:03:41.016844Z","iopub.status.busy":"2023-10-26T08:03:41.016402Z","iopub.status.idle":"2023-10-26T08:03:54.047093Z","shell.execute_reply":"2023-10-26T08:03:54.045010Z","shell.execute_reply.started":"2023-10-26T08:03:41.016810Z"},"id":"N-tBlPrCjORm","trusted":true},"outputs":[],"source":["import math\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from tensorflow import keras \n","from keras import layers\n","import tensorflow_probability as tfp\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T08:04:05.234529Z","iopub.status.busy":"2023-10-26T08:04:05.233474Z","iopub.status.idle":"2023-10-26T08:04:05.240394Z","shell.execute_reply":"2023-10-26T08:04:05.238640Z","shell.execute_reply.started":"2023-10-26T08:04:05.234487Z"},"trusted":true},"outputs":[],"source":["\n","import sys\n","import os"]},{"cell_type":"markdown","metadata":{"id":"bsa4YmyKjORo"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T08:04:09.278534Z","iopub.status.busy":"2023-10-26T08:04:09.277866Z","iopub.status.idle":"2023-10-26T08:04:09.285924Z","shell.execute_reply":"2023-10-26T08:04:09.284139Z","shell.execute_reply.started":"2023-10-26T08:04:09.278493Z"},"id":"MFJIxmMjjORo","trusted":true},"outputs":[],"source":["#data\n","batch_size = 14164\n","\n","\n","# optimization\n","batch_size =  14164      \n","learning_rate = 0.0005 \n","weight_decay = 1e-4 \n","opt = tf.keras.optimizers.Adam(0.0005,beta_1=0.8,beta_2=0.88,epsilon=1e-5)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qdn-Qf4NjORo"},"source":["## Data pipeline\n","\n","We use the\n","[USDA SR Legacy dataset](https://fdc.nal.usda.gov/download-datasets.html)\n"," for encoding the nutrition data of food items. USDA food database has nutrition information of various food items, which can be handy while generating a meal plan to meet the nutritional requirements. Redundant and irrelevent columns are removed and Data set is cleaned. \n","\n"," Below code uses pandas dataframe to preprocess the data. "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T08:04:13.018072Z","iopub.status.busy":"2023-10-26T08:04:13.017375Z","iopub.status.idle":"2023-10-26T08:04:14.642600Z","shell.execute_reply":"2023-10-26T08:04:14.641185Z","shell.execute_reply.started":"2023-10-26T08:04:13.018034Z"},"id":"Tx045hPwnWVw","outputId":"8cf4f42f-b8df-4a0b-915a-48eb3b105304","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Baked Foods' 'Snacks' 'Sweets' 'Vegetables' 'American Indian'\n"," 'Restaurant Foods' 'Beverages' 'Fats and Oils' 'Meats'\n"," 'Dairy and Egg Products' 'Baby Foods' 'Breakfast Cereals'\n"," 'Soups and Sauces' 'Beans and Lentils' 'Fish' 'Fruits' nan\n"," 'Grains and Pasta' 'Nuts and Seeds' 'Prepared Meals' 'Fast Foods'\n"," 'Spices and Herbs' 'Dairy and Egg Products ']\n","cholestol13  vita mcg20  vit c21\n","   Cereals  Vegetables  nuts  pulses  dairy  non-veg  processd  Calories  \\\n","0      0.7         0.0   0.0     0.0    0.0        0         0     307.0   \n","1      0.7         0.0   0.0     0.0    0.0        0         0     330.0   \n","2      0.7         0.0   0.0     0.0    0.0        0         0     377.0   \n","3      0.7         0.0   0.0     0.0    0.0        0         0     232.0   \n","4      0.7         0.0   0.0     0.0    0.0        0         0     273.0   \n","\n","   Fat (g)  Protein (g)  ...  Histidine (mg)  Alanine (mg)  \\\n","0    13.24         5.88  ...             0.0           0.0   \n","1    11.27         4.34  ...             0.0           0.0   \n","2     3.70         6.10  ...             0.0           0.0   \n","3     1.80         8.00  ...             0.0           0.0   \n","4     9.22         6.58  ...           143.0         249.0   \n","\n","   Aspartic acid (mg)  Glutamic acid (mg)  Glycine (mg)  Proline (mg)  \\\n","0                 0.0                 0.0           0.0           0.0   \n","1                 0.0                 0.0           0.0           0.0   \n","2                 0.0                 0.0           0.0           0.0   \n","3                 0.0                 0.0           0.0           0.0   \n","4               406.0              1614.0         214.0         559.0   \n","\n","   Serine (mg)  Hydroxyproline (mg)  Alcohol (g)  Caffeine (mg)  \n","0          0.0                  0.0          0.0            0.0  \n","1          0.0                  0.0          0.0            0.0  \n","2          0.0                  0.0          0.0            0.0  \n","3          0.0                  0.0          0.0            0.0  \n","4        347.0                  0.0          0.0            0.0  \n","\n","[5 rows x 100 columns]\n","(14164, 100)\n","(14164, 100)\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","\"food data\"\n","usda_food = pd.read_csv(\"usda_sr_all_foods.csv\")\n","#usda_food = pd.read_csv(r'C:\\Users\\Harshitha\\Desktop\\usda_sr_all_foods.csv')\n","print(usda_food[\"Food Group\"].unique())\n","usda_food = usda_food.fillna(0)\n","usda_food[\"Cereals\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Baked Foods\" else 1 if x==\"Breakfast Cereals\" else 1 if x==\"Grains and Pasta\" else 0.5 if x==\"Baby Foods\" else 0)\n","usda_food[\"Fruits\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Fruits\" else 0 )\n","usda_food[\"Vegetables\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Vegetables\" else 0 )\n","usda_food[\"nuts\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Nuts and Seeds\" else 0.3 if x==\"Baby Foods\" else 0)\n","usda_food[\"pulses\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Beans and Lentils\" else 0.3 if x==\"Baby Foods\" else 0 )\n","usda_food[\"dairy\"] = usda_food[\"Food Group\"].apply(lambda x: 0.7 if x==\"Dairy and Egg Products\" else 0 )\n","usda_food[\"non-veg\"] = usda_food[\"Food Group\"].apply(lambda x: 1 if x==\"Meats\" else 1 if x==\"Fish\" else 0 )\n","usda_food[\"processd\"] = usda_food[\"Food Group\"].apply(lambda x: 1 if x==\"Beverages\" else 1 if x==\"Fast Foods\" else 1 if x==\"Soups and Sauces\" else 0 )\n","usda_food.drop(columns=[\"Food Group\",\"name\",\"ID\",\"200 Calorie Weight (g)\",\"PRAL score\"], inplace= True)\n","usda_cols = usda_food.columns.to_list()\n","usda_cols = [\"Cereals\",\"Vegetables\",\"nuts\",\"pulses\",\"dairy\",\"non-veg\",\"processd\"]+usda_cols[:-8]\n","print(\"cholestol\"+str(usda_cols.index(\"Cholesterol (mg)\"))+\"  vita mcg\"+str(usda_cols.index(\"Vitamin A, RAE (mcg)\"))+\"  vit c\"+str(usda_cols.index(\"Vitamin C (mg)\")))\n","usda_food = usda_food[usda_cols]\n","print(usda_food.head()); print(usda_food.shape);\n","norm = StandardScaler()\n","usda_norm = norm.fit(usda_food)\n","usda_norm = norm.transform(usda_food); \n","print(usda_norm.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T03:17:35.877298Z","iopub.status.busy":"2023-10-16T03:17:35.876564Z","iopub.status.idle":"2023-10-16T03:17:35.885636Z","shell.execute_reply":"2023-10-16T03:17:35.884416Z","shell.execute_reply.started":"2023-10-16T03:17:35.877263Z"},"id":"miEFFYbjZvOC","trusted":true},"outputs":[],"source":["usda_food = usda_food.sample(n=5000, replace=True)\n","usda_norm = norm.fit_transform(usda_food)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T08:04:16.957757Z","iopub.status.busy":"2023-10-26T08:04:16.957331Z","iopub.status.idle":"2023-10-26T08:04:18.282676Z","shell.execute_reply":"2023-10-26T08:04:18.281011Z","shell.execute_reply.started":"2023-10-26T08:04:16.957714Z"},"id":"E6ixmjctnhnM","outputId":"fb7dbbe9-b69a-4d10-b5d1-b78f7f7134c7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(14164, 1)\n"]}],"source":["from sklearn.neighbors import NearestNeighbors\n","\n","kn = NearestNeighbors(n_neighbors=1).fit(usda_food)\n"]},{"cell_type":"markdown","metadata":{"id":"bxwlNbsgpfz1"},"source":["# VAE architecture\n","\n","Encoder has a dense layer followed by 1D convolutional layers\n","\n","Decoder has sequence of AdaIN blocks of Transpose convolutional layers with instance normalization, sclaed and shifted by factor determined by Dense layer. The dense layer embeds feature information of USDA data distribution. AdaIN block aids in realising highly accurate results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T08:12:52.042222Z","iopub.status.busy":"2023-10-26T08:12:52.041752Z"},"id":"dZpBSiBFpfz1","outputId":"9c22cc62-e1e8-49de-fb3e-e7dc38c8358c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_12 (InputLayer)          [(None, 100, 1)]     0           []                               \n","                                                                                                  \n"," conv1d_27 (Conv1D)             (None, 100, 50)      5050        ['input_12[0][0]']               \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 100, 50)     200         ['conv1d_27[2][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_28 (Conv1D)             (None, 100, 30)      4530        ['batch_normalization_23[2][0]'] \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 100, 30)     120         ['conv1d_28[2][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_29 (Conv1D)             (None, 100, 40)      6040        ['batch_normalization_24[2][0]'] \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 100, 40)     160         ['conv1d_29[2][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_30 (Conv1D)             (None, 50, 30)       6030        ['batch_normalization_25[2][0]'] \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 50, 30)      120         ['conv1d_30[2][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_31 (Conv1D)             (None, 50, 30)       4530        ['batch_normalization_26[2][0]'] \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 50, 30)      120         ['conv1d_31[2][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_32 (Conv1D)             (None, 50, 30)       4530        ['batch_normalization_27[2][0]'] \n","                                                                                                  \n"," conv1d_34 (Conv1D)             (None, 50, 30)       4530        ['batch_normalization_27[2][0]'] \n","                                                                                                  \n"," conv1d_33 (Conv1D)             (None, 50, 1)        151         ['conv1d_32[2][0]']              \n","                                                                                                  \n"," conv1d_35 (Conv1D)             (None, 50, 1)        151         ['conv1d_34[2][0]']              \n","                                                                                                  \n"," tf.compat.v1.squeeze_7 (TFOpLa  (None, 50)          0           ['conv1d_33[2][0]']              \n"," mbda)                                                                                            \n","                                                                                                  \n"," tf.compat.v1.squeeze_8 (TFOpLa  (None, 50)          0           ['conv1d_35[2][0]']              \n"," mbda)                                                                                            \n","                                                                                                  \n"," tf.compat.v1.shape_9 (TFOpLamb  (2,)                0           ['tf.compat.v1.squeeze_7[2][0]'] \n"," da)                                                                                              \n","                                                                                                  \n"," tf.math.multiply_27 (TFOpLambd  (None, 50)          0           ['tf.compat.v1.squeeze_8[2][0]'] \n"," a)                                                                                               \n","                                                                                                  \n"," tf.random.normal_9 (TFOpLambda  (None, 50)          0           ['tf.compat.v1.shape_9[1][0]']   \n"," )                                                                                                \n","                                                                                                  \n"," tf.math.exp_3 (TFOpLambda)     (None, 50)           0           ['tf.math.multiply_27[1][0]']    \n","                                                                                                  \n"," tf.math.multiply_28 (TFOpLambd  (None, 50)          0           ['tf.random.normal_9[1][0]',     \n"," a)                                                               'tf.math.exp_3[1][0]']          \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 100)          0           ['input_12[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_18 (TFOpL  (None, 50)          0           ['tf.math.multiply_28[1][0]',    \n"," ambda)                                                           'tf.compat.v1.squeeze_7[2][0]'] \n","                                                                                                  \n"," dense_31 (Dense)               (None, 5)            505         ['flatten_1[1][0]']              \n","                                                                                                  \n"," tf.expand_dims_10 (TFOpLambda)  (None, 50, 1)       0           ['tf.__operators__.add_18[1][0]']\n","                                                                                                  \n"," conv1d_transpose_10 (Conv1DTra  (None, 100, 70)     420         ['tf.expand_dims_10[1][0]']      \n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_33 (Dense)               (None, 70)           420         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_32 (Dense)               (None, 70)           420         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_9 (Inst  (None, 100, 70)     140         ['conv1d_transpose_10[1][0]']    \n"," anceNormalization)                                                                               \n","                                                                                                  \n"," tf.expand_dims_12 (TFOpLambda)  (None, 1, 70)       0           ['dense_33[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_11 (TFOpLambda)  (None, 1, 70)       0           ['dense_32[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_29 (TFOpLambd  (None, 100, 70)     0           ['instance_normalization_9[1][0]'\n"," a)                                                              , 'tf.expand_dims_12[1][0]']     \n","                                                                                                  \n"," tf.__operators__.add_19 (TFOpL  (None, 100, 70)     0           ['tf.expand_dims_11[1][0]',      \n"," ambda)                                                           'tf.math.multiply_29[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_11 (Conv1DTra  (None, 100, 70)     24570       ['tf.__operators__.add_19[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_35 (Dense)               (None, 70)           420         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_34 (Dense)               (None, 70)           420         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_10 (Ins  (None, 100, 70)     140         ['conv1d_transpose_11[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_14 (TFOpLambda)  (None, 1, 70)       0           ['dense_35[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_13 (TFOpLambda)  (None, 1, 70)       0           ['dense_34[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_30 (TFOpLambd  (None, 100, 70)     0           ['instance_normalization_10[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_14[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_20 (TFOpL  (None, 100, 70)     0           ['tf.expand_dims_13[1][0]',      \n"," ambda)                                                           'tf.math.multiply_30[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_12 (Conv1DTra  (None, 100, 50)     17550       ['tf.__operators__.add_20[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_37 (Dense)               (None, 50)           300         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_36 (Dense)               (None, 50)           300         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_11 (Ins  (None, 100, 50)     100         ['conv1d_transpose_12[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_16 (TFOpLambda)  (None, 1, 50)       0           ['dense_37[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_15 (TFOpLambda)  (None, 1, 50)       0           ['dense_36[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_31 (TFOpLambd  (None, 100, 50)     0           ['instance_normalization_11[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_16[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_21 (TFOpL  (None, 100, 50)     0           ['tf.expand_dims_15[1][0]',      \n"," ambda)                                                           'tf.math.multiply_31[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_13 (Conv1DTra  (None, 100, 30)     7530        ['tf.__operators__.add_21[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_39 (Dense)               (None, 30)           180         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_38 (Dense)               (None, 30)           180         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_12 (Ins  (None, 100, 30)     60          ['conv1d_transpose_13[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_18 (TFOpLambda)  (None, 1, 30)       0           ['dense_39[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_17 (TFOpLambda)  (None, 1, 30)       0           ['dense_38[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_32 (TFOpLambd  (None, 100, 30)     0           ['instance_normalization_12[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_18[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_22 (TFOpL  (None, 100, 30)     0           ['tf.expand_dims_17[1][0]',      \n"," ambda)                                                           'tf.math.multiply_32[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_14 (Conv1DTra  (None, 100, 20)     3020        ['tf.__operators__.add_22[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_41 (Dense)               (None, 20)           120         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_40 (Dense)               (None, 20)           120         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_13 (Ins  (None, 100, 20)     40          ['conv1d_transpose_14[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_20 (TFOpLambda)  (None, 1, 20)       0           ['dense_41[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_19 (TFOpLambda)  (None, 1, 20)       0           ['dense_40[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_33 (TFOpLambd  (None, 100, 20)     0           ['instance_normalization_13[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_20[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_23 (TFOpL  (None, 100, 20)     0           ['tf.expand_dims_19[1][0]',      \n"," ambda)                                                           'tf.math.multiply_33[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_15 (Conv1DTra  (None, 100, 30)     3030        ['tf.__operators__.add_23[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_43 (Dense)               (None, 30)           180         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_42 (Dense)               (None, 30)           180         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_14 (Ins  (None, 100, 30)     60          ['conv1d_transpose_15[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_22 (TFOpLambda)  (None, 1, 30)       0           ['dense_43[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_21 (TFOpLambda)  (None, 1, 30)       0           ['dense_42[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_34 (TFOpLambd  (None, 100, 30)     0           ['instance_normalization_14[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_22[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_24 (TFOpL  (None, 100, 30)     0           ['tf.expand_dims_21[1][0]',      \n"," ambda)                                                           'tf.math.multiply_34[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_16 (Conv1DTra  (None, 100, 50)     150050      ['tf.__operators__.add_24[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_45 (Dense)               (None, 50)           300         ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_44 (Dense)               (None, 50)           300         ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_15 (Ins  (None, 100, 50)     100         ['conv1d_transpose_16[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_24 (TFOpLambda)  (None, 1, 50)       0           ['dense_45[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_23 (TFOpLambda)  (None, 1, 50)       0           ['dense_44[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_35 (TFOpLambd  (None, 100, 50)     0           ['instance_normalization_15[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_24[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_25 (TFOpL  (None, 100, 50)     0           ['tf.expand_dims_23[1][0]',      \n"," ambda)                                                           'tf.math.multiply_35[1][0]']    \n","                                                                                                  \n"," conv1d_transpose_17 (Conv1DTra  (None, 100, 1)      5001        ['tf.__operators__.add_25[1][0]']\n"," nspose)                                                                                          \n","                                                                                                  \n"," dense_47 (Dense)               (None, 1)            6           ['dense_31[1][0]']               \n","                                                                                                  \n"," dense_46 (Dense)               (None, 1)            6           ['dense_31[1][0]']               \n","                                                                                                  \n"," instance_normalization_16 (Ins  (None, 100, 1)      2           ['conv1d_transpose_17[1][0]']    \n"," tanceNormalization)                                                                              \n","                                                                                                  \n"," tf.expand_dims_26 (TFOpLambda)  (None, 1, 1)        0           ['dense_47[1][0]']               \n","                                                                                                  \n"," tf.expand_dims_25 (TFOpLambda)  (None, 1, 1)        0           ['dense_46[1][0]']               \n","                                                                                                  \n"," tf.math.multiply_36 (TFOpLambd  (None, 100, 1)      0           ['instance_normalization_16[1][0]\n"," a)                                                              ',                               \n","                                                                  'tf.expand_dims_26[1][0]']      \n","                                                                                                  \n"," tf.__operators__.add_26 (TFOpL  (None, 100, 1)      0           ['tf.expand_dims_25[1][0]',      \n"," ambda)                                                           'tf.math.multiply_36[1][0]']    \n","                                                                                                  \n"," tf.compat.v1.squeeze_9 (TFOpLa  (None, 100)         0           ['tf.__operators__.add_26[1][0]']\n"," mbda)                                                                                            \n","                                                                                                  \n","==================================================================================================\n","Total params: 252,432\n","Trainable params: 252,072\n","Non-trainable params: 360\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","  6/443 [..............................] - ETA: 14:05:18 - loss: 1.6435 - err:: 0.5911 - cos sim: : -0.2484"]}],"source":["import tensorflow_addons as tfa\n","\n","reg = tf.keras.regularizers.L2(0.0005)\n","adn_reg = tf.keras.regularizers.L2(0.0001)\n","\n","def adainblk(inp,w_nois,out_layers,reg):\n","    x = tfa.layers.InstanceNormalization()(inp)\n","    scl = layers.Dense(out_layers,activation='leaky_relu',kernel_regularizer=reg)(w_nois)\n","    sft = layers.Dense(out_layers),activation='leaky_relu',kernel_regularizer=reg)(w_nois)\n","    adn = tf.expand_dims(scl,axis=-2) + x * tf.expand_dims(sft,axis=-2)\n","    return adn \n","\n","'''--***--auto encoder--***--'''\n","#encoder\n","inp = tf.keras.Input((100))\n","inp = tf.expand_dims(inp,axis=-1)\n","inp = layers.BatchNormalization()(inp)\n","x = layers.Conv1D(50,100,padding='same',activation='leaky_relu',kernel_regularizer=reg)(inp)\n","x = layers.BatchNormalization()(x)\n","x = layers.Conv1D(30,3,activation='leaky_relu',padding='same',kernel_regularizer=reg)(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Conv1D(40,5,activation='leaky_relu',padding='same', kernel_regularizer=reg)(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Conv1D(30,5,strides=2,activation='leaky_relu',padding='same',kernel_regularizer=reg)(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Conv1D(30,5,activation='leaky_relu',padding='same',kernel_regularizer=reg)(x)\n","x = layers.BatchNormalization()(x)\n","x1 = layers.Conv1D(30,5, activation='leaky_relu',padding='same',kernel_regularizer=reg)(x)\n","emb_m = layers.Conv1D(1,5,activation='sigmoid',padding='same')(x1)\n","emb_m = tf.squeeze(emb_m, axis=-1)\n","x2 = layers.Conv1D(30,5, activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(x) \n","emb_v = layers.Conv1D(1,5,activation='sigmoid',padding='same')(x2) \n","emb_v =tf.squeeze(emb_v,axis=-1) \n","nois = tf.random.normal(tf.shape(emb_m)) \n","\n","emb = nois * tf.exp(emb_v * 0.5) + emb_m\n","\n","w_nois =  layers.Dense(15,activation='tanh')(layers.Flatten()(inp)) \n","\n","# decoder \n","x = tf.expand_dims(emb,axis=-1)\n","\n","x = layers.Conv1DTranspose(70,5,strides=2,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(x)\n","adn = adainblk(x,w_nois,70,adn_reg)\n","x = layers.Conv1DTranspose(70,5,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,70,adn_reg)\n","x = layers.Conv1DTranspose(50,5,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,50,adn_reg)\n","x = layers.Conv1DTranspose(30,5,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,30,adn_reg)\n","x = layers.Conv1DTranspose(20,5,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,20,adn_reg)\n","x = layers.Conv1DTranspose(30,5,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,30,adn_reg)\n","x = layers.Conv1DTranspose(50,100,activation=\"leaky_relu\",padding='same',kernel_regularizer=reg)(adn)\n","adn = adainblk(x,w_nois,50,adn_reg)\n","x = layers.Conv1DTranspose(1,100,activation=\"leaky_relu\",padding='same' )(adn)\n","adn = adainblk(x,w_nois,1,adn_reg)\n","out = tf.squeeze(adn,axis=-1)\n","\n","encdr = tf.keras.Model(inp,[emb_m,emb_v])\n","encdec = tf.keras.Model(inp,out) ; \n","encdec.summary()\n","\n","class wlos(tf.keras.losses.Loss):\n","    def call(self,y_true,y_pred):\n","        dif = tfp.math.trapz(tf.math.abs(y_pred - y_true), axis=0)/batch_size ;\n","        return dif  #tf.sqrt(1+tf.square(dif))\n","        #recnst= tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(y_true,y_pred),axis=-1))\n","        #return recnst\n","wloso = wlos()\n","\n","def get_grd(mdl,rel,nois,los):\n","    with tf.GradientTape() as pnlty:\n","         mn,vr = encdr(rel)\n","         kl = -0.5 *(1+vr - tf.square(mn)-tf.exp(vr))\n","         kl = tf.reduce_mean(tf.reduce_sum(kl,axis=-1))\n","\n","    with tf.GradientTape() as grd:\n","        grd.watch(mdl.trainable_variables)\n","        fke = mdl(rel)\n","        lss = los(rel,fke) #lss = los.call(rel,fke)\n","        lss1 = lss # + kl ; #lss1 = tf.reduce_mean(lss1, axis=[0,1]) ; lss1= tf.Variable(lss1) ;print(mdl.trainable_variables[-1], lss1)\n","        return grd.gradient(lss1,mdl.trainable_variables) , lss\n","class wgn(tf.keras.Model):\n","    def __init__(self,mdl,rel,los,opt,grdfn):\n","        super().__init__()\n","        self.mdl = mdl; self.rel = tf.dtypes.cast(rel,tf.float32); self.los=los; self.opt= opt;\n","        #self.opt= tf.keras.optimizers.Adam(0.0005,beta_1=0.8,beta_2=0.88,epsilon=1e-5) \n","        self.grdfn = grdfn \n","    def compile(self,loss,optimizer,metrics): \n","        super().compile() \n","        self.mdl.compile(loss=self.los,optimizer=self.opt,metrics=[\"Accuracy\"]) \n","    def train_step(self,rl):\n","        rel=rl\n","        for i in range(2):\n","            with tf.GradientTape() as grdtp:\n","                grdtp.watch(self.mdl.trainable_variables)\n","                fke = self.mdl(self.rel)\n","                lss = self.los(self.rel,fke) #lss = los.call(rel,fke)\n","                lss1 = lss +1.5*(1+tf.keras.losses.cosine_similarity(self.rel,fke))**2  # + kl ; #lss1 = tf.reduce_mean(lss1, axis=[0,1]) ; lss1= tf.Variable(lss1) ;print(mdl.trainable_variables[-1], lss1)\n","                grd = grdtp.gradient(lss1,self.mdl.trainable_variables)\n","            #grd = tf.reduce_mean(grd,axis=0); print(grd)\n","            self.opt.apply_gradients(zip(grd,self.mdl.trainable_variables))\n","            #mn = tf.reduce_mean(lss) ;\n","            #a = tf.print(mn,[mn],\" loss \")\n","        return {\"loss\":lss1,\"err:\":tf.keras.losses.mean_absolute_error(self.rel,fke),'cos sim: ':tf.keras.losses.cosine_similarity(self.rel,fke)}\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training VAE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class intgrl_los(tf.keras.losses.Loss):\n","    def call(self,y_true,y_pred):\n","        dif = tfp.math.trapz(tf.math.abs(y_pred - y_true), axis=0)/batch_size ;\n","        return dif  \n","\n","wloso = intgrl_los() \n","\n","\n","class vae(tf.keras.Model):\n","    def __init__(self,mdl,real,los,opt):\n","        super().__init__()\n","        self.mdl = mdl; \n","        self.rel = tf.dtypes.cast(real,tf.float32); \n","        self.los=los; \n","        self.opt= opt;      \n","        \n","    def compile(self,loss,optimizer,metrics): \n","        super().compile() \n","        self.mdl.compile(loss=self.los,optimizer=self.opt,metrics=[\"Accuracy\"]) \n","    def train_step(self):\n","        for i in range(2):\n","            with tf.GradientTape() as grdtp:\n","                grdtp.watch(self.mdl.trainable_variables)\n","                fke = self.mdl(self.rel)\n","                lss = self.los(self.rel,fke) \n","                cos_los = tf.keras.losses.cosine_similarity(self.rel,fke)\n","                lss_tot = lss +1.5*(1+cos_los)**2 \n","                grd = grdtp.gradient(lss_tot,self.mdl.trainable_variables)\n","            \n","            self.opt.apply_gradients(zip(grd,self.mdl.trainable_variables))\n","            \n","        return {\"loss\":lss_tot,\" mae:\":tf.keras.losses.mean_absolute_error(self.rel,fke),'cos sim: ':cos_los}\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#training\n","opt = tf.keras.optimizers.Adam(0.0005,beta_1=0.8,beta_2=0.88,epsilon=1e-5)\n","wgno = wgn(encdec,usda_norm,wloso,opt)\n","wgno.compile(loss=wgno.los,optimizer= opt,metrics=[\"Acccuracy\"]) \n","wgno.fit(x,epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#training\n","opt = tf.keras.optimizers.Adam(0.0001,beta_1=0.8,beta_2=0.88,epsilon=1e-5)\n","wgno.compile(loss=wgno.los,optimizer= opt,metrics=[\"Acccuracy\"]) \n","wgno.fit(x,epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"-xuu8K8wjORt"},"source":["## Results\n","\n","Reproduce the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prd = wgno.mdl.predict(usda_norm[15:20])\n","dst,ind = kn.kneighbors(prd)\n","print(\"knn distance: \",dst, \"food index predicted: \",ind)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
